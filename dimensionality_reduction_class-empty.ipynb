{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction - Practical Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is following the progression of the Dimensionality Reduction class. It provides practical illustrations in Python  to understand the notions we have seen in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Author: Fabrice JIMENEZ\n",
    "    \n",
    "Link to course materials: https://github.com/jfabrice/ml-class-dimensionality-reduction\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary loading with Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using this notebook with Google Colab, please execute first the following cells, to retrieve the GitHub repository content, set the working directory and install required dependencies. Otherwise, ignore these 3 cells and move to the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/jfabrice/ml-class-dimensionality-reduction.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('ml-class-dimensionality-reduction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will use for this application is the famous MNIST dataset (handwritten digits). We use the CSV version of this dataset available here: https://pjreddie.com/projects/mnist-in-csv/ \n",
    "\n",
    "We will keep only the mnist_test.csv file, containing 10 000 gray-scale images of dimension 28 x 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/mnist_test.csv', header=None)\n",
    "df['pixels'] = df.index.map(lambda x: np.array(df.iloc[x][1:]))\n",
    "dropcols = df.columns[(df.columns != 0) * (df.columns != 'pixels')]\n",
    "df.drop(dropcols, axis=1, inplace=True)\n",
    "df.columns = ['label','pixels']\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.imshow(df['pixels'][2].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will think about how to distinguish the characteristics of different handwritten digits, starting only from the raw values of the pixels as features.\n",
    "\n",
    "Let's consider 3 digits. Keep them as they are for the moment, you will have time at the end to play with these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Digits considered here ##\n",
    "labels = [1,6,8]\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "X = np.array([df['pixels'][i] for i in df.index if df['label'][i] in labels])\n",
    "y = np.array([df['label'][i] for i in df.index if df['label'][i] in labels])\n",
    "\n",
    "print('X shape: '+str(X.shape))\n",
    "print('y shape: '+str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 28 x 28 = 784 features. It is a high dimension (~ same order of magnitude as the number of points). \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Question: How would you visualize the behavior of the different classes (digits), or find a direction, important features contributing to these classes?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we cannot rely on univariate analysis: it is quite clear that the value of a given pixel on the image will not determine by itself the number which is written. You need to study the relationship between the pixel values: let's see how the methods to reduce dimensionality we saw during this course can help us distinguish noise, correlation and information patterns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Components Analysis: linear approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the PCA\n",
    "pca = PCA(n_components=X.shape[1])\n",
    "XPCA = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose the axes you want to visualize\n",
    "component_x = 1\n",
    "component_y = 2\n",
    "\n",
    "## Plotting\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(len(labels)):\n",
    "    ax.scatter(XPCA[y == labels[i],component_x-1], XPCA[y == labels[i],component_y-1], c=colors[i], label=labels[i], alpha=0.4)\n",
    "\n",
    "l = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Question: Try to visualize different axes and find the ones who allow (or not) to distinguish the classes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-distributed Stochastic Neighbor Embedding: non-linear approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the t-SNE 2D projection\n",
    "\n",
    "## Parameters with real influence on the accuracy\n",
    "perplexity = 30\n",
    "learning_rate = 200\n",
    "n_iter = 1000\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity, learning_rate=learning_rate, n_iter=n_iter)\n",
    "XTSNE = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(len(labels)):\n",
    "    ax.scatter(XTSNE[y == labels[i],0], XTSNE[y == labels[i],1], c=colors[i], label=labels[i], alpha=0.4)\n",
    "l = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Question: Try to visualize the projection by choosing different parameter values. What is the advantage of t-SNE over PCA? What is the inconvenient?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact on supervised model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we consider a supervised Machine Learning model to predict the class of an image (which digit it corresponds to). We will study the impact of dimensionality reduction on 3 classifiers which have different mechanisms:\n",
    "- Naive Bayes Classifier (nb)\n",
    "- SVM Classifier (svm)\n",
    "- Random Forest Classifier (rf)\n",
    "\n",
    "We can give them as features 3 different inputs:\n",
    "- All the pixel values (raw)\n",
    "- The n first PCA components (10 for example)\n",
    "- The 2 dimensions from t-SNE projection (tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_my_model(model, features, test_size):\n",
    "    \n",
    "    ## Building train and test sets from features\n",
    "    if features == 'raw':\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    elif features == 'tsne':\n",
    "        X_train, X_test, y_train, y_test = train_test_split(XTSNE, y, test_size=test_size)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(XPCA[:,:features], y, test_size=test_size)\n",
    "\n",
    "    print(\"Training samples: \"+str(X_train.shape[0]))\n",
    "    print(\"Testing samples: \"+str(X_test.shape[0]))\n",
    "    print(\"Number of features: \"+str(X_train.shape[1]))\n",
    "    \n",
    "    ## Fitting model\n",
    "    if model == 'nb':\n",
    "        clf = GaussianNB()\n",
    "    elif model == 'svm':\n",
    "        clf = SVC(gamma='auto')\n",
    "    elif model == 'rf':\n",
    "        clf = RandomForestClassifier(n_estimators=200, criterion='gini', max_depth=None, max_features=np.min([10, X_train.shape[1]]))\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    ## Printing scores\n",
    "    learningScore = clf.score(X_train, y_train)\n",
    "    generalizationScore = clf.score(X_test, y_test)\n",
    "    print('Learning score: '+str(learningScore))\n",
    "    print('Generalization score: '+str(generalizationScore))\n",
    "    \n",
    "    return generalizationScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Question: Experiment in the cell below by using the function fit_my_model, to check the scores for different configurations\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'svm' ## svm, nb, rf\n",
    "features = 'raw' ## raw, tsne, or Integer corresponding to the n first PCA components\n",
    "test_size = 0.2\n",
    "\n",
    "score = fit_my_model(model, features, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Question: What is the effect of dimensionality reduction on the 3 classifiers? Try to explain why with your intuition...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test all the configurations and build a result table with test scores, to help you answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_table = pd.DataFrame(columns = ['raw', 'pca', 'tsne'], index=['svm', 'nb', 'rf'])\n",
    "for f in comparison_table.columns:\n",
    "    for m in comparison_table.index:\n",
    "        print(f + ' - ' + m)\n",
    "        comparison_table.loc[m,f] = fit_my_model(m, f if f!='pca' else 10, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Heatmap with summarized results\n",
    "fig = sns.heatmap(comparison_table.astype('float'), annot=True, cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Question: What conclusions can you give? If you have time left, you can try with different sets of digits.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These examples concern supervised classifiers only. Can you imagine the impact on other tasks: regression, clustering, anomaly detection... ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always think first about the principles, the intuition, the qualitative aspect behind all the available functions you can find online.\n",
    "\n",
    "- Many people can chain very complex algorithms together and get results which might be relevant for a problem.\n",
    "- Only a few can make the right choices to quickly optimize the resolution of a problem and assess its feasability..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
